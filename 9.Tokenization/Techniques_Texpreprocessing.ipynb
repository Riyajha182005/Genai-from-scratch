{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Riyajha182005/Genai-from-scratch/blob/main/9.Tokenization/Techniques_Texpreprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6jnHynNFPjr"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FI9P2GEwFW1I"
      },
      "source": [
        "Stemming is a process in natural language processing (NLP) that reduces words to their root form. For example, the words \"running,\" \"runs,\" and \"ran\" would all be reduced to the stem \"run.\" This is useful for tasks like searching and text analysis because it allows you to treat different forms of the same word as equivalent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c05bd5d8"
      },
      "outputs": [],
      "source": [
        "words = [\"running\", \"runs\", \"ran\", \"easily\", \"fairly\", \"beautiful\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuGc3msQFVa1"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmZog5LxGvRj"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemming = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOUD-rEKHzn0",
        "outputId": "604d24d3-5ce8-4b27-eba7-65a75051b5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running---->run\n",
            "runs---->run\n",
            "ran---->ran\n",
            "easily---->easili\n",
            "fairly---->fairli\n",
            "beautiful---->beauti\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word + \"---->\" + stemming.stem(word))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3o888t4L5mSX"
      },
      "source": [
        "**PorterStemmer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bLHY0XrIRHc",
        "outputId": "6df95eea-3c0d-4b16-e42f-44f1d5073bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generous---->gener\n",
            "generation---->gener\n",
            "generously---->gener\n",
            "generate---->gener\n"
          ]
        }
      ],
      "source": [
        "## Where its not worked\n",
        "words = [\"generous\",\"generation\",\"generously\",\"generate\"]\n",
        "stemming = PorterStemmer()\n",
        "for word in words:\n",
        "  print(word + \"---->\" + stemming.stem(word))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5073f438"
      },
      "source": [
        "Sometimes, stemming can make words that mean different things look the same. This is a problem because it can be confusing. For example, \"generous,\" \"generation,\" \"generously,\" and \"generate\" all get cut down to \"gener.\" Even though they mean different things, stemming makes them look like the same word. This can be a disadvantage when you need to know the exact meaning of a word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaa1366"
      },
      "source": [
        "**Advantages of Stemming**\n",
        "\n",
        "Despite some disadvantages, stemming is useful in tasks like text classification and sentiment analysis. It helps to:\n",
        "\n",
        "*   Reduce the vocabulary size, making models simpler and faster.\n",
        "*   Group together words with similar meanings, which can improve the accuracy of models that rely on word patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7929540b"
      },
      "source": [
        "**RegexpStemmer Class**\n",
        "\n",
        "The `RegexpStemmer` in NLTK is a stemming tool that uses regular expressions to remove suffixes from words. Unlike rule-based stemmers like the Porter or Snowball stemmers, which apply a predefined set of rules in a specific order, the `RegexpStemmer` allows you to define your own regular expressions to specify which suffixes to remove. This provides more flexibility and control over the stemming process, making it suitable for specific use cases where custom stemming rules are required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JZwVKXhLbHP"
      },
      "outputs": [],
      "source": [
        "from nltk import RegexpStemmer\n",
        "stemmer = RegexpStemmer('ing$|s$|e$|able$', min=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "-4ncxtlL2NZZ",
        "outputId": "6fe66682-c340-4b32-f499-8a2f6711fcc2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'eat'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemmer.stem('eating')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMg64R2L4L7x"
      },
      "outputs": [],
      "source": [
        "from nltk import SnowballStemmer\n",
        "snowball_stemmer=SnowballStemmer('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08G-OOTb4Ylo",
        "outputId": "a3921027-5cf7-4a1d-eaa3-8c9ace5219be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "generous---->generous\n",
            "generation---->generat\n",
            "generously---->generous\n",
            "generate---->generat\n"
          ]
        }
      ],
      "source": [
        "for word in words:\n",
        "  print(word + \"---->\"+snowball_stemmer.stem(word))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJHGQpsu5cPh",
        "outputId": "e3689b90-5793-4aac-f0c0-41f4a7659cfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fairli', 'gener')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stemming.stem('fairly'), stemming.stem('generously')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqVOnQOM6Pic",
        "outputId": "cf0cd7f5-934f-4125-eda0-43d2ee117066"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('fair', 'generous')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snowball_stemmer.stem('fairly'),snowball_stemmer.stem('generously')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3216a95"
      },
      "source": [
        "**Comparison of Porter and Snowball Stemmers**\n",
        "\n",
        "As seen in the outputs above, the Porter Stemmer and Snowball Stemmer can produce different results for the same words. This difference arises from the distinct sets of rules and algorithms they employ for suffix removal. The Snowball Stemmer, often considered a successor to the Porter Stemmer (Porter2), is generally more aggressive and may result in shorter stems. This highlights that the choice of stemming algorithm can impact the final stemmed output and should be considered based on the specific requirements of the NLP task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1f0a93b"
      },
      "source": [
        "**Lemmatization**\n",
        "\n",
        "Lemmatization is another technique in NLP that reduces words to their base or dictionary form, known as the lemma. Unlike stemming, which often just chops off suffixes, lemmatization considers the word's meaning and context to arrive at a valid word. For example, \"running,\" \"runs,\" and \"ran\" would all be reduced to the lemma \"run,\" similar to stemming. However, lemmatization would correctly identify the lemma of \"better\" as \"good,\" whereas a stemmer might just remove the suffix to get \"bett.\" This makes lemmatization more accurate than stemming in preserving the meaning of words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a30b32ac",
        "outputId": "cf448fba-ace5-46a6-e9ee-6b30d0124e88"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30fec93a"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eef3e14f",
        "outputId": "7f682b12-5e1d-4c76-fd5e-7025c0e371e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Lemmatization examples:\n",
            "running ----> running\n",
            "runs ----> run\n",
            "ran ----> ran\n",
            "better ----> better\n",
            "goodness ----> goodness\n"
          ]
        }
      ],
      "source": [
        "# Initialize the WordNet Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Example words\n",
        "words_for_lemmatization = [\"running\", \"runs\", \"ran\", \"better\", \"goodness\"]\n",
        "\n",
        "# Lemmatize the words\n",
        "print(\"Lemmatization examples:\")\n",
        "for word in words_for_lemmatization:\n",
        "    print(f\"{word} ----> {lemmatizer.lemmatize(word)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2c8ad6bc"
      },
      "source": [
        "Note that for \"better\" and \"goodness\", the lemmatizer needs to know the part of speech to give the correct lemma. By default, it assumes the word is a noun."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "856d7451",
        "outputId": "5c279992-1d0e-4c40-c7c7-d2cf77223443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Lemmatization with part of speech:\n",
            "better (adjective) ----> good\n",
            "goodness (noun) ----> goodness\n"
          ]
        }
      ],
      "source": [
        "# Lemmatize with part of speech\n",
        "print(\"\\nLemmatization with part of speech:\")\n",
        "print(f\"better (adjective) ----> {lemmatizer.lemmatize('better', pos='a')}\")\n",
        "print(f\"goodness (noun) ----> {lemmatizer.lemmatize('goodness', pos='n')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5BefSU7OBj_"
      },
      "source": [
        "**Parts of speech**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75facc20"
      },
      "source": [
        "Parts of speech are categories of words based on their grammatical function and meaning within a sentence. Common parts of speech include nouns, verbs, adjectives, adverbs, pronouns, prepositions, conjunctions, and interjections. Identifying the correct part of speech is crucial for accurate lemmatization, as the lemma of a word can vary depending on its grammatical role."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph = \"\"\"I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards, the Greeks, the Turks, the Mughals, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours. Yet we have not done this to any other nation. We have not conquered anyone. We have not grabbed their land, their culture, their history and tried to enforce our way of life on them. Why? Because we believe in freedom, we believe in respecting the freedom of others.\n",
        "\n",
        "This is my first vision, freedom. I believe that India got its first taste of this freedom in 1857, when we started the war of independence. It is this freedom that we must protect and nurture and build on. If we are not free, no one will respect us.\n",
        "\n",
        "My second vision for India is development. For fifty years we have been a developing nation. It is time we see ourselves as a developed nation. We are among the top 5 nations of the world in terms of GDP. We have 10 percent growth rate in most areas. Our poverty levels are falling. Our achievements are being globally recognized today. Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured. Isn't this incorrect?\n",
        "\n",
        "I have a third vision. India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
        "\n",
        "Why are we in India so embarrassed to recognize our strengths, our achievements? We are such a great nation with so much potential. We have the potential for growth. Yet we are held back by our lack of self-confidence.\n",
        "\n",
        "My message to the youth is to have courage, courage to think differently, courage to invent, courage to travel the unexplored path, courage to discover the impossible, courage to conquer the problems and succeed. These are great qualities that they must work towards. This is my message to the youth.\"\"\""
      ],
      "metadata": {
        "id": "2Jf1MPH1b2GQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL1_KuIFd8Q5",
        "outputId": "ca53d0cb-12b8-464a-c457-86886d24685c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "z9bfheJwdi0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caZsqcTKeFWA",
        "outputId": "6159997b-1978-45ef-cbd7-49678a9a138a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I have three visions for India.',\n",
              " 'In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.',\n",
              " 'From Alexander onwards, the Greeks, the Turks, the Mughals, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
              " 'Yet we have not done this to any other nation.',\n",
              " 'We have not conquered anyone.',\n",
              " 'We have not grabbed their land, their culture, their history and tried to enforce our way of life on them.',\n",
              " 'Why?',\n",
              " 'Because we believe in freedom, we believe in respecting the freedom of others.',\n",
              " 'This is my first vision, freedom.',\n",
              " 'I believe that India got its first taste of this freedom in 1857, when we started the war of independence.',\n",
              " 'It is this freedom that we must protect and nurture and build on.',\n",
              " 'If we are not free, no one will respect us.',\n",
              " 'My second vision for India is development.',\n",
              " 'For fifty years we have been a developing nation.',\n",
              " 'It is time we see ourselves as a developed nation.',\n",
              " 'We are among the top 5 nations of the world in terms of GDP.',\n",
              " 'We have 10 percent growth rate in most areas.',\n",
              " 'Our poverty levels are falling.',\n",
              " 'Our achievements are being globally recognized today.',\n",
              " 'Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured.',\n",
              " \"Isn't this incorrect?\",\n",
              " 'I have a third vision.',\n",
              " 'India must stand up to the world.',\n",
              " 'Because I believe that unless India stands up to the world, no one will respect us.',\n",
              " 'Only strength respects strength.',\n",
              " 'We must be strong not only as a military power but also as an economic power.',\n",
              " 'Both must go hand-in-hand.',\n",
              " 'Why are we in India so embarrassed to recognize our strengths, our achievements?',\n",
              " 'We are such a great nation with so much potential.',\n",
              " 'We have the potential for growth.',\n",
              " 'Yet we are held back by our lack of self-confidence.',\n",
              " 'My message to the youth is to have courage, courage to think differently, courage to invent, courage to travel the unexplored path, courage to discover the impossible, courage to conquer the problems and succeed.',\n",
              " 'These are great qualities that they must work towards.',\n",
              " 'This is my message to the youth.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "SZ_11Iu2fj5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hwor9wxAfyku",
        "outputId": "4a7d91c8-1efa-4980-f01b-3fa72bb2d0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I have three visions for India.',\n",
              " 'In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds.',\n",
              " 'From Alexander onwards, the Greeks, the Turks, the Mughals, the Portuguese, the British, the French, the Dutch, all of them came and looted us, took over what was ours.',\n",
              " 'Yet we have not done this to any other nation.',\n",
              " 'We have not conquered anyone.',\n",
              " 'We have not grabbed their land, their culture, their history and tried to enforce our way of life on them.',\n",
              " 'Why?',\n",
              " 'Because we believe in freedom, we believe in respecting the freedom of others.',\n",
              " 'This is my first vision, freedom.',\n",
              " 'I believe that India got its first taste of this freedom in 1857, when we started the war of independence.',\n",
              " 'It is this freedom that we must protect and nurture and build on.',\n",
              " 'If we are not free, no one will respect us.',\n",
              " 'My second vision for India is development.',\n",
              " 'For fifty years we have been a developing nation.',\n",
              " 'It is time we see ourselves as a developed nation.',\n",
              " 'We are among the top 5 nations of the world in terms of GDP.',\n",
              " 'We have 10 percent growth rate in most areas.',\n",
              " 'Our poverty levels are falling.',\n",
              " 'Our achievements are being globally recognized today.',\n",
              " 'Yet we lack the self-confidence to see ourselves as a developed nation, self-reliant and self-assured.',\n",
              " \"Isn't this incorrect?\",\n",
              " 'I have a third vision.',\n",
              " 'India must stand up to the world.',\n",
              " 'Because I believe that unless India stands up to the world, no one will respect us.',\n",
              " 'Only strength respects strength.',\n",
              " 'We must be strong not only as a military power but also as an economic power.',\n",
              " 'Both must go hand-in-hand.',\n",
              " 'Why are we in India so embarrassed to recognize our strengths, our achievements?',\n",
              " 'We are such a great nation with so much potential.',\n",
              " 'We have the potential for growth.',\n",
              " 'Yet we are held back by our lack of self-confidence.',\n",
              " 'My message to the youth is to have courage, courage to think differently, courage to invent, courage to travel the unexplored path, courage to discover the impossible, courage to conquer the problems and succeed.',\n",
              " 'These are great qualities that they must work towards.',\n",
              " 'This is my message to the youth.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56rwhrjIrfMg",
        "outputId": "7eb108c9-0d6b-4cdf-d840-c28e7d4ba2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Name Entity Recognization**"
      ],
      "metadata": {
        "id": "eTH6hoEcCxio"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea69a9c6"
      },
      "source": [
        "Try this sentence:\n",
        "\n",
        "\"In 2023, over 500,000 tourists visited the Eiffel Tower in Paris, France.\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"In 2023, over 500,000 tourists visited the Eiffel Tower in Paris, France.\""
      ],
      "metadata": {
        "id": "W335xsBPC4YC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "002e260d",
        "outputId": "d7577438-e78e-4c15-91e9-c67153d5a3fc"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "words=nltk.word_tokenize(sentence)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0YX8__dEhdI",
        "outputId": "fad97859-402a-4287-c489-1806498c9134"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['In',\n",
              " '2023',\n",
              " ',',\n",
              " 'over',\n",
              " '500,000',\n",
              " 'tourists',\n",
              " 'visited',\n",
              " 'the',\n",
              " 'Eiffel',\n",
              " 'Tower',\n",
              " 'in',\n",
              " 'Paris',\n",
              " ',',\n",
              " 'France',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('maxent_ne_chunker_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGATmiIXEwfn",
        "outputId": "be55952a-4c1f-4bd7-d9b7-fdaefe2f99dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagged_words = nltk.pos_tag(words)"
      ],
      "metadata": {
        "id": "VRUlu8FXEsH7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('words')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYbOsGsRFbFe",
        "outputId": "23a54f1a-cdaa-45dd-f23d-e401b02c969f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "named_entities = nltk.ne_chunk(tagged_words)\n",
        "print(named_entities)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bJaSzqWFIF4",
        "outputId": "e5ed8937-2b2f-4ab4-8daf-076636e7374a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  In/IN\n",
            "  2023/CD\n",
            "  ,/,\n",
            "  over/IN\n",
            "  500,000/CD\n",
            "  tourists/NNS\n",
            "  visited/VBD\n",
            "  the/DT\n",
            "  (ORGANIZATION Eiffel/NNP Tower/NNP)\n",
            "  in/IN\n",
            "  (GPE Paris/NNP)\n",
            "  ,/,\n",
            "  (GPE France/NNP)\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5904a89d"
      },
      "source": [
        "Based on the output from the Named Entity Recognition code, here's an explanation of the identified entities in the sentence \"In 2023, over 500,000 tourists visited the Eiffel Tower in Paris, France.\":\n",
        "\n",
        "*   `(ORGANIZATION Eiffel/NNP Tower/NNP)`: This identifies \"Eiffel Tower\" as an Organization. In this context, NLTK has incorrectly tagged it as an organization. It should ideally be tagged as a Facility or Location.\n",
        "*   `(GPE Paris/NNP)`: This identifies \"Paris\" as a GPE (Geo-Political Entity). This is correct, as Paris is a city.\n",
        "*   `(GPE France/NNP)`: This identifies \"France\" as a GPE (Geo-Political Entity). This is also correct, as France is a country.\n",
        "\n",
        "The output also includes other tokens and their parts of speech (e.g., `In/IN`, `2023/CD`, `visited/VBD`), which are not named entities but are part of the tokenization and tagging process."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFmBw9fQ+IO7GXrn2IOyU1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}